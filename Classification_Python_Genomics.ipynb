{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Classification_Python_Genomics.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "RkavSLmBoBE3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_caN2j0FoR7y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "823rW-QYofPU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "To make sure that every single line will be  printed, even if they're in the same cell, we can use thf ollowing config:"
      ]
    },
    {
      "metadata": {
        "id": "H1rVke7zoXxM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DFtAz0sBpwhH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Build a directory and name it *ML_Python_PMCRT* in your colab directory in google drive. Then upload the two files \"CCLE_ExpMat_Top500Genes.csv\" and \"CCLE_ExpMat_Pheno.csv\" in this directory."
      ]
    },
    {
      "metadata": {
        "id": "F_4iR4uRolYE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "CCLE_exp = pd.read_csv('/content/gdrive/My Drive/Colab Notebooks/ML_Python_PMCRT/CCLE_ExpMat_Top500Genes.csv', index_col=0)\n",
        "CCLE_pheno = pd.read_csv('/content/gdrive/My Drive/Colab Notebooks/ML_Python_PMCRT/CCLE_ExpMat_Pheno.csv', index_col=0)\n",
        "####\n",
        "print(\"shape of the expression dataframe:\", CCLE_exp.shape)\n",
        "print(\"shape of the expression dataframe:\", CCLE_pheno.shape)\n",
        "####\n",
        "CCLE_exp = CCLE_exp.transpose()\n",
        "n_samples, n_features = CCLE_exp.shape\n",
        "\n",
        "\n",
        "CCLE_exp.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zQ2n1Y-yonb9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import collections\n",
        "collections.Counter(CCLE_pheno.loc[:,\"tissueid\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dOhHFFulo9x4",
        "colab_type": "code",
        "outputId": "bfd7ea85-331f-4b6c-e935-1d126851a58f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "type(np.where(CCLE_pheno.loc[:,\"tissueid\"] == 'breast'))\n",
        "type(np.where(CCLE_pheno.loc[:,\"tissueid\"] == 'breast')[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tuple"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "4f3CgpKypWPO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "collections.Counter(np.where(CCLE_pheno.loc[:,\"tissueid\"] == 'breast')[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4FTIUi_Pp-2d",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We need to convert the labels, tissue names, to numbers."
      ]
    },
    {
      "metadata": {
        "id": "l1NO4AZWpln4",
        "colab_type": "code",
        "outputId": "12fcb838-704d-47b8-85ed-02e4f1408fd6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing\n",
        "le = preprocessing.LabelEncoder()\n",
        "\n",
        "le.fit(CCLE_pheno.loc[:,\"tissueid\"])\n",
        "y=le.transform(CCLE_pheno.loc[:,\"tissueid\"])\n",
        "\n",
        "collections.Counter(y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LabelEncoder()"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({0: 54, 1: 49, 2: 170, 3: 57, 4: 172, 5: 48})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "uAK2Auu3qZm6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "CCLE_pheno['Encoded_tissue'] = y\n",
        "CCLE_pheno.columns.values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "T18GQ3dArCsh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Types of observations\n",
        "\n",
        "There are three types of data measurements or variables we deal with in building machine learning models.\n",
        "\n",
        "* **Nominal**:\n",
        "*Nominal* (categorical or qualitative) variables or observations are labels without any order or quantitative difference between the label classes. Examples of nominal data are tissue type, healthy versus malignant tissue, male versus female, etc.\n",
        "* **Ordinal**:\n",
        "For *ordinal* variables, order of the values assigned (or tested) for each sample is important.  Examples of ordinal data are tumor stage, level of satisfaction about a product, etc.\n",
        "* **Interval**:\n",
        "For *Interval* variables, both order and exact difference between the data points matter. Examples of ordinal data are tumor size and age.\n",
        "\n",
        "# Building classification models\n",
        "\n",
        "Among the available classification methods in Python, we focus on the following five to build classification models of tissue type of the cancer cell lines in our dataset:\n",
        "\n",
        "* Logistic regression\n",
        "* K- nearest neighbour\n",
        "* Naive Bayes\n",
        "* Random forest\n",
        "* Support vector machine"
      ]
    },
    {
      "metadata": {
        "id": "DRsL_8AG5Gio",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Logistic regression\n",
        "If we have set of features X1 to Xn, y can be obtained as:\n",
        "\\begin{equation*} y=b0+b1X1+b2X2+...+bnXn\\end{equation*}\n",
        "\n",
        "where y is the predicted value obtained by weighted sum of the feature values.\n",
        "\n",
        "Then probability of each class (for example tissue class BREAST) can be obtained using the logistic function \n",
        "\n",
        "\\begin{equation*} p(class=BREAST)=\\frac{1}{(1+exp(-y))} \\end{equation*}\n",
        "\n",
        "Based on the given class labels and the features given in the trainign data, coefficients b0 to bn can be ontained during the optimization process.\n",
        "\n",
        "b0 to bn are fixed for all samples while X1 to Xn are feature values specific to each sample. Hence, the logistic function will give us probability of each class assigned to each sample. Finally, the model will choose the class with the highest probability for each sample.\n",
        "\n",
        "\n",
        "**Note.** The logistic regression model is parametric and the parameters are the regression coefficiets b0 to bn.\n"
      ]
    },
    {
      "metadata": {
        "id": "74gD0HCTq46K",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Initialize our classifier\n",
        "logreg = LogisticRegression()\n",
        "\n",
        "# Fitting the model with the data\n",
        "logreg.fit(CCLE_exp, y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dtLh3ecg5p49",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_pred = logreg.predict(CCLE_exp)\n",
        "print(y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "H1q-alBXNXt1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Checking the accuracy of the model"
      ]
    },
    {
      "metadata": {
        "id": "czDelzU5LiAe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "print(\"accuracy of the predictions:\", metrics.accuracy_score(y, y_pred))\n",
        "print(\"blanced accuracy of the predictions:\", metrics.balanced_accuracy_score(y, y_pred))\n",
        "print(\"MCC of the predictions:\", metrics.matthews_corrcoef(y, y_pred))\n",
        "print(\"Confusion matrix of the predictions:\", metrics.confusion_matrix(y, y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "760dcRUxL2Q9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Splitting data to training and testing sets\n",
        "\n",
        "To investigate performance of our model, we need to split the data to training and testing sets. This will help us to check potential overfitting in our model training."
      ]
    },
    {
      "metadata": {
        "id": "irWyuGQ0LrNL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(CCLE_exp, y, test_size=0.4, random_state=5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EkfPdEc1NNuB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Training a logistic regression model on the training set:"
      ]
    },
    {
      "metadata": {
        "id": "nS5ZJMA-MD0P",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "logreg = LogisticRegression()\n",
        "\n",
        "# Fitting the model with the data\n",
        "logreg.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KbRJjzTCNTIH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Testing the model on the testing set:"
      ]
    },
    {
      "metadata": {
        "id": "rL02ix-jMLqy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_pred_test = logreg.predict(X_test)\n",
        "print(y_pred_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Fh4PyUBqMOuG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(\"accuracy of the predictions:\", metrics.accuracy_score(y_test, y_pred_test))\n",
        "print(\"blanced accuracy of the predictions:\", metrics.balanced_accuracy_score(y_test, y_pred_test))\n",
        "print(\"MCC of the predictions:\", metrics.matthews_corrcoef(y_test, y_pred_test))\n",
        "print(\"Confusion matrix of the predictions:\", metrics.confusion_matrix(y_test, y_pred_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dYZKd0aAPPGZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# K nearest neighbour(k-NN)\n",
        "\n",
        "K nearest neighbour uses a distance metric like Euclidean distance to identity similarity of target data point (sample) in test or validation set to the data points (samples) in the trainign set. Then based on the user specified k, it finds the k closest points (samples) to the target data point. Afterward, it chooses the most frequent label among the k closes points (majority voting) as the class label of the target sample. The class labels can be also assigned based on weighted voting of the k closest data points to the data point.\n",
        "\n",
        "**Note.** The k nearest neighbour is non-parametric.\n"
      ]
    },
    {
      "metadata": {
        "id": "xTqwSBCzMUMy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# Initialize our classifier\n",
        "knn = KNeighborsClassifier()\n",
        "\n",
        "# Fitting the model with the data\n",
        "knn.fit(CCLE_exp, y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "16xM3v69PhAo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_pred = knn.predict(CCLE_exp)\n",
        "print(y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZSuig7RfPlls",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(\"accuracy of the predictions:\", metrics.accuracy_score(y, y_pred))\n",
        "print(\"blanced accuracy of the predictions:\", metrics.balanced_accuracy_score(y, y_pred))\n",
        "print(\"MCC of the predictions:\", metrics.matthews_corrcoef(y, y_pred))\n",
        "print(\"Confusion matrix of the predictions:\", metrics.confusion_matrix(y, y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "udBwVh4aPoub",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "knn = KNeighborsClassifier()\n",
        "\n",
        "# Fitting the model with the data\n",
        "knn.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1-eAlq3PP2Vs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Testing the model on the testing set:"
      ]
    },
    {
      "metadata": {
        "id": "MnrCi5zcP2rF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_pred_test = knn.predict(X_test)\n",
        "print(y_pred_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QqxZjdr9P6iP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(\"accuracy of the predictions:\", metrics.accuracy_score(y_test, y_pred_test))\n",
        "print(\"blanced accuracy of the predictions:\", metrics.balanced_accuracy_score(y_test, y_pred_test))\n",
        "print(\"MCC of the predictions:\", metrics.matthews_corrcoef(y_test, y_pred_test))\n",
        "print(\"Confusion matrix of the predictions:\", metrics.confusion_matrix(y_test, y_pred_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "62cLiquCQdd7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Naive Bayes\n",
        "To understand Naive Bayes algotirhm, we need to know what Bayes theorem. Bayes theorem related conditional rpobabilities as follows:\n",
        "\n",
        "\\begin{equation*} p(A|B)p(B)=p(B|A)p(A) \\end{equation*}\n",
        "that can be rewritten as\n",
        "\n",
        "\\begin{equation*} p(A|B)=\\frac{p(B|A)p(A)}{p(B)} \\end{equation*}\n",
        "\n",
        "where p(A) and p(B) are probabilities of events A and B, respectively. p(A|B) and p(B|A) are also conditional probabilities of A given B and B given A, respectively.\n",
        "**Example without numbers**\n",
        "\n",
        "Now let's assume we have 3 features X1, X2 and X3 and we want to identify the probability of class C for sample A with feature values *x1*, *x2* and *x3*:\n",
        "\n",
        "\\begin{equation*} p(class=C|X1=x1, X2=x2 , X3=x3)=\\frac{p(X1=x1|class=C)p(X2=x2|lass=C)p(X3=x3|class=C)p(class=C)}{p(X1=x1)p(X2=x2)p(X3=x3)} \\end{equation*}\n",
        "\n",
        "where \n",
        "\\begin{equation*} p(X1=x1, X2=x2 , X3=x3)=p(X1=x1)p(X2=x2)p(X3=x3) \\end{equation*}\n",
        "and\n",
        "\\begin{equation*} p(X1=x1, X2=x2 , X3=x3|class=C)=p(X1=x1|class=C)p(X2=x2|class=C)p(X3=x3|lass=C)p(class=C) \\end{equation*}\n",
        "\n",
        "as the features are independent variables. \n",
        "\n",
        "**Real life example with numbers**\n",
        "We want to know the chance of having breast cancer if the diagnosis test is positive for a woman with the age between 40 and 60. This example is mainly for understanding Bayes theorem not Naive Bayes classifier. In case of Naive Bayes algorithm, this process can be easily extended to multiple features as described in the above example.\n",
        "\n",
        "***Assumptions (not necessarily correct)***\n",
        "* 2% of women between 40 and 60 have breast cancer\n",
        "* True positive rate is 95% (if a woman has breast cancer, it will be diagnosed with 95% probability). Therefore, 5% of the time the women without breast cancer will be diagnosed positively by the test.\n",
        "\n",
        "Now the question is *What is the chance of havign breast cancer if a woman has positive result from a diagnosis test?*\n",
        "\n",
        "\\begin{equation*} p(having \\quad breast \\quad cancer|positive)=\\frac{p(positive|breast \\quad cancer)p(breast cancer)}{p(positive)} \\end{equation*}\n",
        "\n",
        "where \n",
        "\n",
        "\n",
        "\\begin{equation*} p(positive) = p(positive|having \\quad breast \\quad cancer)p(having \\quad breast \\quad cancer) \\\\+ p(positive|not \\quad having \\quad breast \\quad cancer)p(not \\quad having \\quad breast \\quad cancer)\\\\=\n",
        "0.95*0.02+0.05*0.98\\\\=0.068\\end{equation*}\n",
        "\n",
        "Therefore,\n",
        "\n",
        "\\begin{equation*} p(having \\quad breast  \\quad cancer|positive)=\\frac{p(positive|breast \\quad cancer)p(having \\quad breast \\quad cancer)}{p(positive)}\\\\= \\frac{0.95*0.02}{0.068}\\\\=0.28\\end{equation*}\n",
        "\n",
        "\n",
        "As we can see, there is only 28% chance of having cancer upon positive test result. Although the numbers were not clinically valid numbers, we deal with similar results in disease diagnosis. This is one of the reasons that further checkups by phycisions are mandatory upon positive results. Do not panic when you have a positive result but follow up with your doctor immediately."
      ]
    },
    {
      "metadata": {
        "id": "7yafr4ZVP9cY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "# Initialize our classifier\n",
        "gnb = GaussianNB()\n",
        "\n",
        "# Train our classifier\n",
        "model = gnb.fit(CCLE_exp, y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CQxu_bSpQ6LA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_pred = knn.predict(CCLE_exp)\n",
        "print(y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bag66EQ7Q-IU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(\"accuracy of the predictions:\", metrics.accuracy_score(y, y_pred))\n",
        "print(\"blanced accuracy of the predictions:\", metrics.balanced_accuracy_score(y, y_pred))\n",
        "print(\"MCC of the predictions:\", metrics.matthews_corrcoef(y, y_pred))\n",
        "print(\"Confusion matrix of the predictions:\", metrics.confusion_matrix(y, y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VpZA-bjiQ_tj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "gnb = GaussianNB()\n",
        "\n",
        "# Fitting the model with the data\n",
        "gnb.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rMFl22-JRGYw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Testing the model on the testing set:"
      ]
    },
    {
      "metadata": {
        "id": "SPN2o7qBRD7j",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_pred_test = knn.predict(X_test)\n",
        "print(y_pred_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Bnr5IfAlRIit",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(\"accuracy of the predictions:\", metrics.accuracy_score(y_test, y_pred_test))\n",
        "print(\"blanced accuracy of the predictions:\", metrics.balanced_accuracy_score(y_test, y_pred_test))\n",
        "print(\"MCC of the predictions:\", metrics.matthews_corrcoef(y_test, y_pred_test))\n",
        "print(\"Confusion matrix of the predictions:\", metrics.confusion_matrix(y_test, y_pred_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ea3EHEAFmSB_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}