{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Classification_Python_Genomics.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "RkavSLmBoBE3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_caN2j0FoR7y",
        "colab_type": "code",
        "outputId": "7830f144-0d52-495a-ebed-f7db08ce0889",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "823rW-QYofPU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "To make sure that every single line will be  printed, even if they're in the same cell, we can use thf ollowing config:"
      ]
    },
    {
      "metadata": {
        "id": "H1rVke7zoXxM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DFtAz0sBpwhH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Build a directory and name it *ML_Python_PMCRT* in your colab directory in google drive. Then upload the two files \"CCLE_ExpMat_Top500Genes.csv\" and \"CCLE_ExpMat_Pheno.csv\" in this directory."
      ]
    },
    {
      "metadata": {
        "id": "F_4iR4uRolYE",
        "colab_type": "code",
        "outputId": "7f49797c-48bf-426c-c52f-a78fe92447ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "CCLE_exp = pd.read_csv('/content/gdrive/My Drive/Colab Notebooks/ML_Python_PMCRT/CCLE_ExpMat_Top500Genes.csv', index_col=0)\n",
        "CCLE_pheno = pd.read_csv('/content/gdrive/My Drive/Colab Notebooks/ML_Python_PMCRT/CCLE_ExpMat_Pheno.csv', index_col=0)\n",
        "####\n",
        "print(\"shape of the expression dataframe:\", CCLE_exp.shape)\n",
        "print(\"shape of the expression dataframe:\", CCLE_pheno.shape)\n",
        "####\n",
        "CCLE_exp = CCLE_exp.transpose()\n",
        "n_samples, n_features = CCLE_exp.shape\n",
        "\n",
        "\n",
        "CCLE_exp.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shape of the expression dataframe: (500, 550)\n",
            "shape of the expression dataframe: (550, 17)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(550, 500)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "zQ2n1Y-yonb9",
        "colab_type": "code",
        "outputId": "f9c61240-16ac-483b-b816-a2d2887e0405",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "cell_type": "code",
      "source": [
        "import collections\n",
        "collections.Counter(CCLE_pheno.loc[:,\"tissueid\"])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({'breast': 54,\n",
              "         'central_nervous_system': 49,\n",
              "         'haematopoietic_and_lymphoid_tissue': 170,\n",
              "         'large_intestine': 57,\n",
              "         'lung': 172,\n",
              "         'skin': 48})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "dOhHFFulo9x4",
        "colab_type": "code",
        "outputId": "856d6b61-eab7-48c7-ef90-2706c6f904bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "type(np.where(CCLE_pheno.loc[:,\"tissueid\"] == 'breast'))\n",
        "type(np.where(CCLE_pheno.loc[:,\"tissueid\"] == 'breast')[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tuple"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "4f3CgpKypWPO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "collections.Counter(np.where(CCLE_pheno.loc[:,\"tissueid\"] == 'breast')[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4FTIUi_Pp-2d",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We need to convert the labels, tissue names, to numbers."
      ]
    },
    {
      "metadata": {
        "id": "l1NO4AZWpln4",
        "colab_type": "code",
        "outputId": "f1bfa300-38d1-4909-f705-f0c21f90dab3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing\n",
        "le = preprocessing.LabelEncoder()\n",
        "\n",
        "le.fit(CCLE_pheno.loc[:,\"tissueid\"])\n",
        "y=le.transform(CCLE_pheno.loc[:,\"tissueid\"])\n",
        "\n",
        "collections.Counter(y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LabelEncoder()"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({0: 54, 1: 49, 2: 170, 3: 57, 4: 172, 5: 48})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "uAK2Auu3qZm6",
        "colab_type": "code",
        "outputId": "4560e24e-3fb9-4e08-b266-022a1ee5b263",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        }
      },
      "cell_type": "code",
      "source": [
        "CCLE_pheno['Encoded_tissue'] = y\n",
        "CCLE_pheno.columns.values"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['cellid', 'tissueid', 'CCLE.cellid', 'link', 'CCLE.name',\n",
              "       'Cell.line.primary.name', 'Cell.line.aliases', 'Gender',\n",
              "       'Site.Primary', 'Histology', 'Hist.Subtype1', 'Notes', 'Source',\n",
              "       'Expression.arrays', 'SNP.arrays', 'Oncomap',\n",
              "       'Hybrid.Capture.Sequencing', 'Encoded_tissue'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "T18GQ3dArCsh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Types of observations\n",
        "\n",
        "There are three types of data measurements or variables we deal with in building machine learning models.\n",
        "\n",
        "* **Nominal**:\n",
        "*Nominal* (categorical or qualitative) variables or observations are labels without any order or quantitative difference between the label classes. Examples of nominal data are tissue type, healthy versus malignant tissue, male versus female, etc.\n",
        "* **Ordinal**:\n",
        "For *ordinal* variables, order of the values assigned (or tested) for each sample is important.  Examples of ordinal data are tumor stage, level of satisfaction about a product, etc.\n",
        "* **Interval**:\n",
        "For *Interval* variables, both order and exact difference between the data points matter. Examples of ordinal data are tumor size and age.\n",
        "\n",
        "# Building classification models\n",
        "\n",
        "Among the available classification methods in Python, we focus on the following five to build classification models of tissue type of the cancer cell lines in our dataset:\n",
        "\n",
        "* Logistic regression\n",
        "* K- nearest neighbour\n",
        "* Naive Bayes\n",
        "* Random forest\n",
        "* Support vector machine"
      ]
    },
    {
      "metadata": {
        "id": "DRsL_8AG5Gio",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Logistic regression\n",
        "If we have set of features X1 to Xn, y can be obtained as:\n",
        "\\begin{equation*} y=b0+b1X1+b2X2+...+bnXn\\end{equation*}\n",
        "\n",
        "where y is the predicted value obtained by weighted sum of the feature values.\n",
        "\n",
        "Then probability of each class (for example tissue class BREAST) can be obtained using the logistic function \n",
        "\n",
        "\\begin{equation*} p(class=BREAST)=\\frac{1}{(1+exp(-y))} \\end{equation*}\n",
        "\n",
        "Based on the given class labels and the features given in the trainign data, coefficients b0 to bn can be ontained during the optimization process.\n",
        "\n",
        "b0 to bn are fixed for all samples while X1 to Xn are feature values specific to each sample. Hence, the logistic function will give us probability of each class assigned to each sample. Finally, the model will choose the class with the highest probability for each sample.\n",
        "\n",
        "\n",
        "**Note.** The logistic regression model is parametric and the parameters are the regression coefficiets b0 to bn.\n"
      ]
    },
    {
      "metadata": {
        "id": "74gD0HCTq46K",
        "colab_type": "code",
        "outputId": "c9feeab3-d2e4-4782-bb87-8394f80bab66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression as LR\n",
        "\n",
        "# Initialize our classifier\n",
        "#logreg = LogisticRegression()\n",
        "logreg = LR()\n",
        "\n",
        "# Fitting the model with the data\n",
        "logreg.fit(CCLE_exp, y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
            "  \"this warning.\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
              "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
              "          tol=0.0001, verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "dtLh3ecg5p49",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_pred = logreg.predict(CCLE_exp)\n",
        "print(y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "H1q-alBXNXt1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Checking the accuracy of the model"
      ]
    },
    {
      "metadata": {
        "id": "czDelzU5LiAe",
        "colab_type": "code",
        "outputId": "2b422160-7725-40e4-ee33-01834f78219d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "print(\"accuracy of the predictions:\", metrics.accuracy_score(y,y_pred))\n",
        "print(\"precision of the predictions:\", metrics.precision_score(y,y_pred, average=\"macro\"))\n",
        "print(\"blanced accuracy of the predictions:\", metrics.balanced_accuracy_score(y, y_pred))\n",
        "print(\"MCC of the predictions:\", metrics.matthews_corrcoef(y, y_pred))\n",
        "print(\"Confusion matrix of the predictions:\", metrics.confusion_matrix(y, y_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy of the predictions: 1.0\n",
            "precision of the predictions: 1.0\n",
            "blanced accuracy of the predictions: 1.0\n",
            "MCC of the predictions: 1.0\n",
            "Confusion matrix of the predictions: [[ 54   0   0   0   0   0]\n",
            " [  0  49   0   0   0   0]\n",
            " [  0   0 170   0   0   0]\n",
            " [  0   0   0  57   0   0]\n",
            " [  0   0   0   0 172   0]\n",
            " [  0   0   0   0   0  48]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "760dcRUxL2Q9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Splitting data to training and testing sets\n",
        "\n",
        "To investigate performance of our model, we need to split the data to training and testing sets. This will help us to check potential overfitting in our model training."
      ]
    },
    {
      "metadata": {
        "id": "irWyuGQ0LrNL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(CCLE_exp, y, test_size=0.4, random_state=5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EkfPdEc1NNuB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Training a logistic regression model on the training set:"
      ]
    },
    {
      "metadata": {
        "id": "nS5ZJMA-MD0P",
        "colab_type": "code",
        "outputId": "d7101314-e20c-44d5-8586-510a8f4a9440",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        }
      },
      "cell_type": "code",
      "source": [
        "logreg = LogisticRegression()\n",
        "\n",
        "# Fitting the model with the data\n",
        "logreg.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
            "  \"this warning.\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
              "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
              "          tol=0.0001, verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "metadata": {
        "id": "KbRJjzTCNTIH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Testing the model on the testing set:"
      ]
    },
    {
      "metadata": {
        "id": "rL02ix-jMLqy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_pred_test = logreg.predict(X_test)\n",
        "print(y_pred_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WdtraPkEQCa7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Performance measures\n",
        "\n",
        "To assess performance of the machine learning model, we can use one or few of the following measures of the performance of the model:\n",
        "\n",
        "* **Accuracy**: This measure gives you a sense of performance for all the classes together as follows:\n",
        "\n",
        "\\begin{equation*} Accuracy=\\frac{Number\\:of\\:correct\\:predictions}{(Total\\:number\\:of\\:data\\:points (samples))} \\end{equation*}\n",
        "\n",
        "In case of binary classification, considering two groups of positive and negative samples, accuracy can be re-written as follows:\n",
        "\n",
        "\\begin{equation*} Accuracy=\\frac{TP+TN}{(TP+TN+FP+FN)} \\end{equation*}\n",
        "\n",
        "Note. In case of imbalance in your classes, even a terrible classifier may result in high accuracy. As an example, assume you have 100 samples, 80 positive and 20 negative. Accuracy of a model that predict every sample is positive could be 0.8:\n",
        "\n",
        "\\begin{equation*} Accuracy=\\frac{80+0}{(80+0+20+0)} = 0.8 \\end{equation*}\n",
        "\n",
        "which can be a model with zero weight for all the features and a positive intercept (constant in the model).\n",
        "\n",
        "* **Precision**: Precision cares about true classification of a target class and is defined as follows:\n",
        "\n",
        "\\begin{equation*} Precision=\\frac{TP}{(TP+FP)} \\end{equation*}\n",
        "\n",
        "As you may have noticed, the same issue holds for precision in case of imbalanced data. The precision of the same example model will be 0.8.\n",
        "\n",
        "* **Recall (or sensitivity)**: Recall tells you the probability of retreival of target population using the develped model and is defined as follows: \n",
        "\n",
        "\\begin{equation*} Recall=\\frac{TP}{(TP+FN)} \\end{equation*}\n",
        "\n",
        "Considering the same example, recall of the model with only an intercept term could be equal to 1:\n",
        "\n",
        "\\begin{equation*} Recall=\\frac{80}{(80+0)} \\end{equation*}\n",
        "\n",
        "* **Specificity (or selectivity)**:  Specificity is define\n",
        "\n",
        "\\begin{equation*} Specificity=\\frac{TN}{(TN+FP)} \\end{equation*}\n",
        "\n",
        "Specificity of the example model will be equal to 0 which could help us to figure out that the given model was not a good one.\n",
        "\n",
        "* **Balanced accuracy**: Balanced accuracy is difned as the average of the recall and specificity:\n",
        "\n",
        "\n",
        "\\begin{equation*} Balanced\\:accuracy=\\frac{Recall+Specificity}{2}\\end{equation*}\n",
        "\n",
        "Hence, the balanced accuracy of the example model will be 0.5.\n",
        "\n",
        "* **Confusion matrix (or error matrix)**: True and false classification of the samples in all the classes can be shown in a matrix which is called confusion (or error) matrix. The columsn are usually considered as the actual classes and rows as predicted classes. Hence, the diagonal elements of the matrix will be the total number of true classifcation in each class. \n",
        "\n",
        "* **Matthews correlation coefficient (MCC)**: MCC is one of the best meaures to summarize the confusion matrix with a little bit more complex definitions as follows: \n",
        "\n",
        "\\begin{equation*} MCC=\\frac{TP*TN-FP*FN}{\\sqrt{(TP+FP)(TP+FN)(TN+FP)(TN+FN)}}\\end{equation*}\n"
      ]
    },
    {
      "metadata": {
        "id": "Fh4PyUBqMOuG",
        "colab_type": "code",
        "outputId": "58cfc688-7729-44ee-b19e-83303aaf8b76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"accuracy of the predictions:\", metrics.accuracy_score(y_test, y_pred_test))\n",
        "print(\"blanced accuracy of the predictions:\", metrics.balanced_accuracy_score(y_test, y_pred_test))\n",
        "print(\"MCC of the predictions:\", metrics.matthews_corrcoef(y_test, y_pred_test))\n",
        "print(\"Confusion matrix of the predictions:\", metrics.confusion_matrix(y_test, y_pred_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy of the predictions: 0.9409090909090909\n",
            "blanced accuracy of the predictions: 0.9147621019488467\n",
            "MCC of the predictions: 0.9226665524020982\n",
            "Confusion matrix of the predictions: [[15  0  0  0  1  0]\n",
            " [ 1 16  0  0  2  1]\n",
            " [ 0  0 65  0  1  2]\n",
            " [ 0  0  0 23  2  0]\n",
            " [ 0  0  0  1 72  0]\n",
            " [ 0  0  1  0  1 16]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dYZKd0aAPPGZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# K nearest neighbour(k-NN)\n",
        "\n",
        "K nearest neighbour uses a distance metric like Euclidean distance to identity similarity of target data point (sample) in test or validation set to the data points (samples) in the trainign set. Then based on the user specified k, it finds the k closest points (samples) to the target data point. Afterward, it chooses the most frequent label among the k closes points (majority voting) as the class label of the target sample. The class labels can be also assigned based on weighted voting of the k closest data points to the data point.\n",
        "\n",
        "**Note.** The k nearest neighbour is non-parametric.\n"
      ]
    },
    {
      "metadata": {
        "id": "xTqwSBCzMUMy",
        "colab_type": "code",
        "outputId": "ddbb8599-56d8-4ff5-ccb2-5f1497fb062d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# Initialize our classifier\n",
        "knn = KNeighborsClassifier(n_neighbors=10)\n",
        "\n",
        "# Fitting the model with the data\n",
        "knn.fit(CCLE_exp, y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
              "           metric_params=None, n_jobs=None, n_neighbors=10, p=2,\n",
              "           weights='uniform')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "metadata": {
        "id": "16xM3v69PhAo",
        "colab_type": "code",
        "outputId": "13d9bb1c-9f3d-4817-e877-0c172d388a17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "cell_type": "code",
      "source": [
        "y_pred = knn.predict(CCLE_exp)\n",
        "print(y_pred)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2 1 5 1 5 4 5 2 2 4 4 1 2 0 4 2 2 0 0 1 2 3 5 2 4 4 0 4 4 4 4 4 0 1 1 4 2\n",
            " 2 4 4 3 5 5 5 5 5 4 4 4 4 3 4 1 2 2 1 2 1 4 4 4 4 4 2 4 3 0 2 4 2 2 4 5 1\n",
            " 1 2 1 1 3 1 4 0 1 0 0 0 4 4 0 0 4 0 3 3 1 2 2 2 4 4 0 2 5 3 3 2 4 5 5 2 2\n",
            " 2 1 2 2 2 2 2 3 2 2 1 4 1 1 2 2 2 2 2 4 4 4 2 3 4 2 3 3 3 3 4 4 4 5 2 0 0\n",
            " 1 0 4 0 0 5 0 2 5 5 5 2 2 2 2 2 2 2 2 2 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
            " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
            " 3 4 4 4 4 4 4 4 4 4 4 4 3 4 4 4 4 1 2 2 1 2 2 2 4 2 2 3 2 4 3 2 1 2 2 2 4\n",
            " 4 1 1 1 1 5 4 2 3 4 2 5 5 5 5 5 5 4 2 1 3 2 2 2 2 1 3 3 3 4 1 3 3 3 4 3 0\n",
            " 3 1 2 2 1 1 2 1 5 5 0 0 5 1 1 0 1 2 2 2 2 0 3 2 4 3 3 3 3 3 5 4 4 4 4 4 4\n",
            " 2 2 4 0 2 2 2 1 2 3 4 4 4 0 4 4 0 3 4 0 4 4 4 4 4 4 4 3 4 4 4 4 2 4 4 5 2\n",
            " 0 5 0 5 0 5 0 2 5 0 4 1 0 5 5 0 0 5 0 5 0 5 5 5 5 5 3 2 2 5 2 4 2 2 2 2 2\n",
            " 5 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 1 2 0 2 2 1 5 4 3 4 1 2 4 1 2 2 2 2 4 2\n",
            " 2 2 2 2 2 2 4 2 2 2 2 4 4 4 4 3 4 4 4 4 4 4 1 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
            " 3 2 2 2 2 2 2 2 2 2 3 2 2 2 2 2 2 4 4 4 4 1 2 2 2 0 5 3 3 1 3 3 1 3 5 1 4\n",
            " 3 1 4 3 3 3 3 4 2 2 2 2 2 2 2 2 4 3 4 2 1 5 2 2 5 5 5 5 5 2 0 2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZSuig7RfPlls",
        "colab_type": "code",
        "outputId": "112276cc-af73-41b1-a98d-fa437c0b5cf4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"accuracy of the predictions:\", metrics.accuracy_score(y, y_pred))\n",
        "print(\"blanced accuracy of the predictions:\", metrics.balanced_accuracy_score(y, y_pred))\n",
        "print(\"MCC of the predictions:\", metrics.matthews_corrcoef(y, y_pred))\n",
        "print(\"Confusion matrix of the predictions:\", metrics.confusion_matrix(y, y_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy of the predictions: 0.9018181818181819\n",
            "blanced accuracy of the predictions: 0.8687430557244885\n",
            "MCC of the predictions: 0.8732937382402157\n",
            "Confusion matrix of the predictions: [[ 37   3   0   1  13   0]\n",
            " [  0  44   0   0   3   2]\n",
            " [  0   1 160   0   2   7]\n",
            " [  0   1   0  49   4   3]\n",
            " [  2   2   0   4 164   0]\n",
            " [  3   1   0   0   2  42]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "udBwVh4aPoub",
        "colab_type": "code",
        "outputId": "48d76242-40d4-481f-d582-0599f349801f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "cell_type": "code",
      "source": [
        "knn = KNeighborsClassifier()\n",
        "\n",
        "# Fitting the model with the data\n",
        "knn.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
              "           metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
              "           weights='uniform')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "metadata": {
        "id": "1-eAlq3PP2Vs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Testing the model on the testing set:"
      ]
    },
    {
      "metadata": {
        "id": "MnrCi5zcP2rF",
        "colab_type": "code",
        "outputId": "f070c276-5e02-4651-aaca-98eadd0b9a01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        }
      },
      "cell_type": "code",
      "source": [
        "y_pred_test = knn.predict(X_test)\n",
        "print(y_pred_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[4 0 2 3 4 0 3 2 2 2 2 0 3 4 4 4 2 2 4 4 4 2 1 4 1 0 2 5 4 0 4 2 5 1 2 4 0\n",
            " 4 2 2 1 3 4 4 2 2 2 0 4 2 2 4 2 2 4 4 1 4 2 2 4 4 4 4 5 3 0 0 0 3 5 2 3 3\n",
            " 5 2 4 4 4 2 4 4 3 0 3 4 1 4 4 4 2 4 4 4 5 2 5 2 1 4 4 4 4 2 2 3 2 4 0 2 4\n",
            " 1 2 5 2 2 2 4 4 2 1 4 3 4 5 2 5 1 4 1 0 2 2 4 0 2 3 2 1 4 2 4 2 4 2 4 2 5\n",
            " 3 3 3 5 2 2 2 2 4 4 2 4 3 4 3 5 4 2 4 4 4 3 0 0 4 2 2 2 2 4 2 2 4 2 4 2 2\n",
            " 4 3 2 2 4 4 4 1 3 1 5 4 0 4 5 4 4 0 4 2 4 2 5 3 4 5 3 1 4 5 2 2 2 3 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "QqxZjdr9P6iP",
        "colab_type": "code",
        "outputId": "c7cdd424-de9f-4302-81ad-ee8dc8046873",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"accuracy of the predictions:\", metrics.accuracy_score(y_test, y_pred_test))\n",
        "print(\"blanced accuracy of the predictions:\", metrics.balanced_accuracy_score(y_test, y_pred_test))\n",
        "print(\"MCC of the predictions:\", metrics.matthews_corrcoef(y_test, y_pred_test))\n",
        "print(\"Confusion matrix of the predictions:\", metrics.confusion_matrix(y_test, y_pred_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy of the predictions: 0.9090909090909091\n",
            "blanced accuracy of the predictions: 0.8755370892649297\n",
            "MCC of the predictions: 0.8804643029362605\n",
            "Confusion matrix of the predictions: [[13  0  0  0  3  0]\n",
            " [ 0 16  0  0  3  1]\n",
            " [ 0  0 65  0  1  2]\n",
            " [ 1  0  0 23  1  0]\n",
            " [ 3  0  1  1 68  0]\n",
            " [ 1  0  2  0  0 15]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "62cLiquCQdd7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Naive Bayes\n",
        "To understand Naive Bayes algotirhm, we need to know what Bayes theorem. Bayes theorem related conditional rpobabilities as follows:\n",
        "\n",
        "\\begin{equation*} p(A|B)p(B)=p(B|A)p(A) \\end{equation*}\n",
        "that can be rewritten as\n",
        "\n",
        "\\begin{equation*} p(A|B)=\\frac{p(B|A)p(A)}{p(B)} \\end{equation*}\n",
        "\n",
        "where p(A) and p(B) are probabilities of events A and B, respectively. p(A|B) and p(B|A) are also conditional probabilities of A given B and B given A, respectively.\n",
        "**Example without numbers**\n",
        "\n",
        "Now let's assume we have 3 features X1, X2 and X3 and we want to identify the probability of class C for sample A with feature values *x1*, *x2* and *x3*:\n",
        "\n",
        "\\begin{equation*} p(class=C|X1=x1, X2=x2 , X3=x3)=\\frac{p(X1=x1|class=C)p(X2=x2|lass=C)p(X3=x3|class=C)p(class=C)}{p(X1=x1)p(X2=x2)p(X3=x3)} \\end{equation*}\n",
        "\n",
        "where \n",
        "\\begin{equation*} p(X1=x1, X2=x2 , X3=x3)=p(X1=x1)p(X2=x2)p(X3=x3) \\end{equation*}\n",
        "and\n",
        "\\begin{equation*} p(X1=x1, X2=x2 , X3=x3|class=C)=p(X1=x1|class=C)p(X2=x2|class=C)p(X3=x3|lass=C)p(class=C) \\end{equation*}\n",
        "\n",
        "as the features are independent variables. \n",
        "\n",
        "**Real life example with numbers**\n",
        "We want to know the chance of having breast cancer if the diagnosis test is positive for a woman with the age between 40 and 60. This example is mainly for understanding Bayes theorem not Naive Bayes classifier. In case of Naive Bayes algorithm, this process can be easily extended to multiple features as described in the above example.\n",
        "\n",
        "***Assumptions (not necessarily correct)***\n",
        "* 2% of women between 40 and 60 have breast cancer\n",
        "* True positive rate is 95% (if a woman has breast cancer, it will be diagnosed with 95% probability). Therefore, 5% of the time the women without breast cancer will be diagnosed positively by the test.\n",
        "\n",
        "Now the question is *What is the chance of havign breast cancer if a woman has positive result from a diagnosis test?*\n",
        "\n",
        "\\begin{equation*} p(having \\quad breast \\quad cancer|positive)=\\frac{p(positive|breast \\quad cancer)p(breast cancer)}{p(positive)} \\end{equation*}\n",
        "\n",
        "where \n",
        "\n",
        "\n",
        "\\begin{equation*} p(positive) = p(positive|having \\quad breast \\quad cancer)p(having \\quad breast \\quad cancer) \\\\+ p(positive|not \\quad having \\quad breast \\quad cancer)p(not \\quad having \\quad breast \\quad cancer)\\\\=\n",
        "0.95*0.02+0.05*0.98\\\\=0.068\\end{equation*}\n",
        "\n",
        "Therefore,\n",
        "\n",
        "\\begin{equation*} p(having \\quad breast  \\quad cancer|positive)=\\frac{p(positive|breast \\quad cancer)p(having \\quad breast \\quad cancer)}{p(positive)}\\\\= \\frac{0.95*0.02}{0.068}\\\\=0.28\\end{equation*}\n",
        "\n",
        "\n",
        "As we can see, there is only 28% chance of having cancer upon positive test result. Although the numbers were not clinically valid numbers, we deal with similar results in disease diagnosis. This is one of the reasons that further checkups by phycisions are mandatory upon positive results. Do not panic when you have a positive result but follow up with your doctor immediately.\n",
        "\n",
        "**Note.** Naive Bayes classifier is called ***Naive*** as it assumes each feature will independently contribute in prediction of a class for each data point (sample)."
      ]
    },
    {
      "metadata": {
        "id": "7yafr4ZVP9cY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "# Initialize our classifier\n",
        "gnb = GaussianNB()\n",
        "\n",
        "# Train our classifier\n",
        "model = gnb.fit(CCLE_exp, y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CQxu_bSpQ6LA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_pred = knn.predict(CCLE_exp)\n",
        "print(y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bag66EQ7Q-IU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(\"accuracy of the predictions:\", metrics.accuracy_score(y, y_pred))\n",
        "print(\"blanced accuracy of the predictions:\", metrics.balanced_accuracy_score(y, y_pred))\n",
        "print(\"MCC of the predictions:\", metrics.matthews_corrcoef(y, y_pred))\n",
        "print(\"Confusion matrix of the predictions:\", metrics.confusion_matrix(y, y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VpZA-bjiQ_tj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "gnb = GaussianNB()\n",
        "\n",
        "# Fitting the model with the data\n",
        "gnb.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rMFl22-JRGYw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Testing the model on the testing set:"
      ]
    },
    {
      "metadata": {
        "id": "SPN2o7qBRD7j",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_pred_test = knn.predict(X_test)\n",
        "print(y_pred_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Bnr5IfAlRIit",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(\"accuracy of the predictions:\", metrics.accuracy_score(y_test, y_pred_test))\n",
        "print(\"blanced accuracy of the predictions:\", metrics.balanced_accuracy_score(y_test, y_pred_test))\n",
        "print(\"MCC of the predictions:\", metrics.matthews_corrcoef(y_test, y_pred_test))\n",
        "print(\"Confusion matrix of the predictions:\", metrics.confusion_matrix(y_test, y_pred_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ea3EHEAFmSB_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}